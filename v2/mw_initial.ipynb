{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "77ccdab4-886d-46a0-9537-53ec4a0f37e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pprint\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../methods')))\n",
    "from marked_words import marked_words \n",
    "\n",
    "# def pprint(dic):\n",
    "#     full_list = []\n",
    "#     for word in sorted(dic, key=lambda x: x[1], reverse=True):\n",
    "#         full_list.append(word[0])\n",
    "#     return full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "f7addad3-1c3d-4782-9ee5-6125ed8f7934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_gpt_4o = pd.read_csv('../new_data/gpt-4o/gpt-4o_personas.csv')\n",
    "df_gpt_4 = pd.read_csv('../new_data/gpt-4/gpt-4_personas.csv')\n",
    "df_gpt_4_turbo = pd.read_csv('../new_data/gpt-4-turbo/gpt-4-turbo_personas.csv')\n",
    "df_gemini = pd.read_csv('../new_data/gemini/gemini_personas.csv')\n",
    "df_gpt_35_turbo = pd.read_csv('../new_data/gpt-3.5-turbo/gpt-3.5-turbo-0125_personas.csv')\n",
    "df_llama3 = pd.read_csv('../new_data/llama3/meta-llama/Llama-3-70b-chat-hf_personas.csv')\n",
    "df_mixtral = pd.read_csv('../new_data/mixtral/mistralai/Mixtral-8x22B-Instruct-v0.1_personas.csv')\n",
    "\n",
    "titles = [\n",
    "    'GPT-4o_Dataset',\n",
    "    'GPT-4_Dataset',\n",
    "    'GPT-4_Turbo_Dataset',\n",
    "    'Gemini-1.5-Flash_Dataset',\n",
    "    'GPT-3.5_Turbo_Dataset',\n",
    "    'Llama-3_Dataset',\n",
    "    'Mixtral_Dataset'\n",
    "]\n",
    "\n",
    "dfs = [df_gpt_4o, df_gpt_4, df_gpt_4_turbo, df_gemini, df_gpt_35_turbo, df_llama3, df_mixtral]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "146cb3a5-c30a-44e8-98cb-369cbc27cf78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean text and drop NA values\n",
    "for df in dfs:\n",
    "    df['text_clean'] = df['text'].str.lower().str.replace('[^\\w\\s]', '', regex=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "# for title, df in zip(titles, dfs):\n",
    "#     print(f\"{title}\\n{'=' * len(title)}\")\n",
    "#     display(df[\"prompt_num\"].value_counts())\n",
    "#     display(df[\"gender\"].value_counts())\n",
    "#     display(df[\"race\"].value_counts())\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "201b11ba-8600-4e13-8e54-5c90fb870a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "\n",
      "Processing: GPT-4o_Dataset\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing: GPT-4_Dataset\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing: GPT-4_Turbo_Dataset\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing: Gemini-1.5-Flash_Dataset\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing: GPT-3.5_Turbo_Dataset\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing: Llama-3_Dataset\n",
      "\n",
      "--------------------\n",
      "\n",
      "Processing: Mixtral_Dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dv_gpt4o_mw = {}\n",
    "dv_gpt4_mw = {}\n",
    "dv_gpt4t_mw = {}\n",
    "dv_gemini_mw = {}\n",
    "dv_gpt35t_mw = {}\n",
    "dv_llama3_mw = {}\n",
    "dv_mixtral_mw = {}\n",
    "\n",
    "datasets_dict = {\n",
    "    'GPT-4o_Dataset': (df_gpt_4o, dv_gpt4o_mw),\n",
    "    'GPT-4_Dataset': (df_gpt_4, dv_gpt4_mw),\n",
    "    'GPT-4_Turbo_Dataset': (df_gpt_4_turbo, dv_gpt4t_mw),\n",
    "    'Gemini-1.5-Flash_Dataset': (df_gemini, dv_gemini_mw),\n",
    "    'GPT-3.5_Turbo_Dataset': (df_gpt_35_turbo, dv_gpt35t_mw),\n",
    "    'Llama-3_Dataset': (df_llama3, dv_llama3_mw),\n",
    "    'Mixtral_Dataset': (df_mixtral, dv_mixtral_mw)\n",
    "}\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "unmarked_genders = ['N', 'W']\n",
    "\n",
    "for title in titles:\n",
    "    \n",
    "    # Print the title\n",
    "    print(\"--------------------\\n\")\n",
    "    print(f\"Processing: {title}\\n\")\n",
    "   \n",
    "    df, dv_mw = datasets_dict[title]\n",
    "    \n",
    "    # Process by race\n",
    "    # print(\"Processing by: race\\n\")\n",
    "    for race in df['race'].unique():\n",
    "        outs = marked_words(df, [race], ['race'], ['a White'])\n",
    "        # print(f\"pp.pprint(outs) - {race}:\\n\")\n",
    "        # pp.pprint(outs)\n",
    "        # print(\"\\n\")\n",
    "        dv_mw[race] = outs\n",
    "\n",
    "    temps = []\n",
    "    for race in df['race'].unique():\n",
    "        temp = marked_words(df, ['a White'], ['race'], [race])\n",
    "        # print(f\"pp.pprint(temp) - {race}:\\n\")\n",
    "        # pp.pprint(temp)\n",
    "        # print(\"\\n\")\n",
    "        temps.extend([item for sublist in temp for item in sublist]) # Flatten the list\n",
    "\n",
    "    # seen = Counter(temps).most_common()\n",
    "    # dv_mw['a White'] = [w for w, c in seen if c == 4]\n",
    "    dv_mw['a White'] = temps\n",
    "    \n",
    "    # Process by gender\n",
    "    # print(\"Processing by: gender\\n\")\n",
    "    for gender in df['gender'].unique():\n",
    "        outs = marked_words(df, [gender], ['gender'], ['M'])\n",
    "        # print(f\"pp.pprint(outs) - {gender}:\\n\")\n",
    "        # pp.pprint(outs)\n",
    "        # print(\"\\n\")\n",
    "        dv_mw[gender] = outs\n",
    "\n",
    "    temps = []\n",
    "    for gender in df['gender'].unique():\n",
    "        temp = marked_words(df, ['M'], ['gender'], [gender])\n",
    "        # print(f\"pp.pprint(temp) - {gender}:\\n\")\n",
    "        # pp.pprint(temp)\n",
    "        # print(\"\\n\")\n",
    "        temps.extend([item for sublist in temp for item in sublist])  # Flatten the list\n",
    "        \n",
    "    # seen = Counter(temps).most_common()\n",
    "    # dv_mw['M'] = [w for w, c in seen if c == 2]\n",
    "    dv_mw['M'] = temps\n",
    "    \n",
    "    # Top words for intersectional groups\n",
    "    # print(\"Processing Top words for intersectional groups\\n\")\n",
    "    for race in df['race'].unique():\n",
    "        for gen in df['gender'].unique():\n",
    "            # dv_mw[race + ' ' + gen] = marked_words(df, [race, gen], ['race', 'gender'], ['a White', 'M'])\n",
    "            outs = marked_words(df, [race, gen], ['race', 'gender'], ['a White', 'M'])\n",
    "            # print(f\"pp.pprint(outs[{race}_{gen}]):\\n\")\n",
    "            # pp.pprint(outs)\n",
    "            # print(\"\\n\")\n",
    "            dv_mw[race + '_' + gen]  = outs\n",
    "            \n",
    "    temps = []        \n",
    "    for race in df['race'].unique():\n",
    "        for gen in df['gender'].unique():\n",
    "            # dv_mw[race + ' ' + gen] = marked_words(df, [race, gen], ['race', 'gender'], ['a White', 'M'])\n",
    "            temp = marked_words(df, ['a White', 'M'], ['race', 'gender'], [race, gen])\n",
    "            # print(f\"pp.pprint(temp[{race}_{gen}]):\\n\")\n",
    "            # pp.pprint(temp)\n",
    "            # print(\"\\n\")\n",
    "            temps.extend([item for sublist in temp for item in sublist])  # Flatten the list\n",
    "    \n",
    "    # seen = Counter(temps).most_common()\n",
    "    # dv_mw['a White M'] = [w for w, c in seen]\n",
    "    dv_mw['a White_M'] = temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "6e541ba2-721b-4af0-9d20-592c9594368a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pp.pprint(dv_gpt4o_mw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "5d18b455-84c7-44a2-b389-eac61fe04eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mw_dicts = [dv_gpt4o_mw, dv_gpt4_mw, dv_gpt4t_mw, dv_gemini_mw, dv_gpt35t_mw, dv_llama3_mw, dv_mixtral_mw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "185016e1-44ee-4a24-950c-f8105b9a4002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Formatting and sorting the words within each key of every model\n",
    "\n",
    "for dv_mw in mw_dicts:\n",
    "    \n",
    "    # Iterate through each key-value pair in dv_m\n",
    "    for key, value in dv_mw.items():\n",
    "        # Check if the value is empty\n",
    "        if not value:\n",
    "            dv_mw[key] = []  # Assign an empty list if the value is empty\n",
    "            continue\n",
    "\n",
    "        # Check if the value is a list of tuples or a flat list\n",
    "        if isinstance(value[0], list):  # If it's a list of tuples\n",
    "            words_scores = value\n",
    "        else:  # If it's a flat list\n",
    "            words_scores = [(value[i], value[i+1]) for i in range(0, len(value), 2)]\n",
    "\n",
    "        # Sort the list by z-score in descending order\n",
    "        sorted_words_scores = sorted(words_scores, key=lambda x: x[1], reverse=True)\n",
    "        sig_words = sorted_words_scores\n",
    "\n",
    "        # Store the result in the dv_mw dictionary\n",
    "        dv_mw[key] = sig_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "01692f18-c1c6-4810-aa06-88c8a3d30ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pp.pprint(dv_gemini_mw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "e1ddf47e-9622-4cff-aff2-71981a096837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removing Duplicate words within each key of every model\n",
    "\n",
    "for dv_mw in mw_dicts:\n",
    "    # Iterate through each key in top_ten_words\n",
    "    for key in dv_mw:\n",
    "        seen_words = set()  # A set to keep track of words we've already encountered\n",
    "        unique_list = []  # A new list to store unique tuples\n",
    "\n",
    "        for word, score in dv_mw[key]:\n",
    "            if word not in seen_words:\n",
    "                seen_words.add(word)  # Add the word to the set\n",
    "                unique_list.append((word, score))  # Add the tuple to the unique list\n",
    "\n",
    "        # Update the dictionary with the list of unique words\n",
    "        dv_mw[key] = unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "9deaa9da-bf4b-483f-894c-039f00d63ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pp.pprint(dv_gpt4o_mw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "a6c351ec-a8e2-4616-bb98-b92369247690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at: ../new_data/mp-analysis-data/llm-mw/gpt4o_mw.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-mw/gpt4_mw.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-mw/gpt4-turbo_mw.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-mw/gemini1.5-flash_mw.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-mw/gpt3.5-turbo_mw.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-mw/llama-3_mw.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-mw/mixtral_mw.csv\n"
     ]
    }
   ],
   "source": [
    "# Creating csv files based on dictionary of every model\n",
    "output_dir = '../new_data/mp-analysis-data/llm-mw'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model_names = [\n",
    "    'gpt4o',\n",
    "    'gpt4',\n",
    "    'gpt4-turbo',\n",
    "    'gemini1.5-flash',\n",
    "    'gpt3.5-turbo',\n",
    "    'llama-3',\n",
    "    'mixtral'\n",
    "]\n",
    "\n",
    "races = ['a Black', 'an Asian', 'a Latino', 'a Middle-Eastern', 'a White']\n",
    "genders = ['M', 'W', 'N']\n",
    "\n",
    "for model, dv_mw in zip(model_names, mw_dicts):\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for key, words in dv_mw.items():\n",
    "        race, gender = '', ''\n",
    "\n",
    "        if key in races:\n",
    "            race = key\n",
    "        elif key in genders:\n",
    "            gender = key\n",
    "        elif '_' in key:\n",
    "            race, gender = key.split('_')\n",
    "\n",
    "        mw_captured_words = [(word,score) for word, score in words]\n",
    "\n",
    "        # # If there's more than one word, join them with commas; otherwise, just use the single word\n",
    "        # top_words = ', '.join(word_list) if word_list else ''\n",
    "\n",
    "        data.append([race, gender, mw_captured_words])\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data, columns=['race', 'gender', 'mw_captured_words'])\n",
    "\n",
    "    # Directory and name format of the csv file\n",
    "    df.to_csv(f'{output_dir}/{model}_mw.csv', index=False)\n",
    "\n",
    "    print(f\"CSV file saved at: {output_dir}/{model}_mw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "c8deece2-d1cb-47ec-9def-f0419c5a62b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selecting only the top ten words of every key for every model and removing irrelevant words\n",
    "\n",
    "gpt4o_top_ten = {}\n",
    "gpt4_top_ten = {}\n",
    "gpt4_turbo_top_ten = {}\n",
    "gemini_top_ten = {}\n",
    "gpt35_turbo_top_ten = {}\n",
    "llama3_top_ten = {}\n",
    "mixtral_top_ten = {}\n",
    "\n",
    "llms_top_ten_dicts = [gpt4o_top_ten, gpt4_top_ten, gpt4_turbo_top_ten, gemini_top_ten, \n",
    "                      gpt35_turbo_top_ten, llama3_top_ten, mixtral_top_ten]\n",
    "\n",
    "for dv_mw, llm_dict in zip(mw_dicts, llms_top_ten_dicts):\n",
    "\n",
    "    # Iterate through each key-value pair in dv_gpt4o_mw\n",
    "    for key, value in dv_mw.items():\n",
    "        # Select the top ten words\n",
    "        top_ten = value[:10]\n",
    "        # Store the result in the top_ten_words dictionary\n",
    "        llm_dict[key] = top_ten\n",
    "\n",
    "\n",
    "words_to_remove = ['', ' ', 'the', 'and', 'or', 'this', 'that',\n",
    "                   'he', 'his', 'him', 'man',\n",
    "                   'they', 'their', 'them', 'nonbinary',\n",
    "                   'she', 'hers', 'her', 'woman',\n",
    "                   'black',\n",
    "                   'latino', 'latina', 'latin', 'de',\n",
    "                   'middleeast', 'middleeastern', 'middle-east', 'middle-eastern',\n",
    "                   'east', 'eastern', 'middle',\n",
    "                   'white',\n",
    "                   'asian', 'asia', 'continent']\n",
    "\n",
    "for llm_dict in llms_top_ten_dicts:\n",
    "    for key in llm_dict:\n",
    "        llm_dict[key] = [tup for tup in llm_dict[key] if tup[0] not in words_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ddbd3e2d-cbb6-462b-908b-d3ba80ce0fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pp.pprint(gpt4o_top_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "ec817ada-3fd1-4bca-8078-ccf47da1b3f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at: ../new_data/mp-analysis-data/llm-top-words/gpt4o_top_ten_words.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-top-words/gpt4_top_ten_words.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-top-words/gpt4-turbo_top_ten_words.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-top-words/gemini1.5-flash_top_ten_words.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-top-words/gpt3.5-turbo_top_ten_words.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-top-words/llama-3_top_ten_words.csv\n",
      "CSV file saved at: ../new_data/mp-analysis-data/llm-top-words/mixtral_top_ten_words.csv\n"
     ]
    }
   ],
   "source": [
    "# Creating a csv file for top_ten_words_filtered named 'gpt4o_top_words.csv'\n",
    "\n",
    "output_dir = '../new_data/mp-analysis-data/llm-top-words'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for model, llm_dict in zip(model_names, llms_top_ten_dicts):\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for key, words in llm_dict.items():\n",
    "        race, gender = '', ''\n",
    "\n",
    "        if key in races:\n",
    "            race = key\n",
    "        elif key in genders:\n",
    "            gender = key\n",
    "        elif '_' in key:\n",
    "            race, gender = key.split('_')\n",
    "\n",
    "        # Extract just the words and ignoring the scores\n",
    "        top_ten_words = [(word,score) for word, score in words]\n",
    "\n",
    "        data.append([race, gender, top_ten_words])\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data, columns=['race', 'gender', 'top_ten_words'])\n",
    "\n",
    "    # Directory and name format of the csv file\n",
    "    df.to_csv(f'{output_dir}/{model}_top_ten_words.csv', index=False)\n",
    "\n",
    "    print(f\"CSV file saved at: {output_dir}/{model}_top_ten_words.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aea987-facf-4b2d-b4c0-89f3b79fce6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
